[model]
anthropic.api_key = 'YOUR_API_KEY'
anthropic.model = 'claude-3-sonnet-20240229'
anthropic.use = true # Use the Anthropic model to generate data

openai.api_key = 'YOUR_API_KEY'
openai.model = 'gpt-4-turbo'
openai.use = false # Use the OpenAI model to generate data (cannot be used with the Anthropic model)

[general]
output_dir = 'output'
language = 'en'
wiki_lang = 'en' # Language to use for the Wikipedia API
use_wiki = true # Use the Wikipedia API to get articles for the tasks

num_topics = 200
topic_generation_temperature = 0.7
topic_generation_max_tokens = 400

llm_task_types = [
    'question_answering',
    'multiple_choice',
    'summarization',
    'translation',
    'creative_writing',
    'conversation',
    'jokes',
    'debate'
]

# Filters to apply to the response
response_filters = [
  'my programming',
  'openai',
  'language model',
  'large language',
  'as an? (ai|generative language|gpt|bot)',
  'illegal and dangerous',
  "i do(n't| not) (possess|have|exhibit) (personal|consciousness|subjective)",
  'personal (feelings|thoughts|emotions|desires|experiences|goals|objective|belief)',
  "(can('t| ?not)|w(on't|will not)|unable.?) (\\w+\\s)+(with (that|your)|your \\w+|provide)",
  'my limitations',
  'the limitations of my',
  'my abilities',
  'violates my',
  "i (can('t| ?not)|w(on't|will not)|am (not |un)able.?).{0,30}(you are|you're|your )",
  'please note that',
  'flesch'
]

[culture]
enabled = true
num_topics = 400
prompt = 'You are a native Thai person with expert knowledge of Thai culture, history, language, and customs. Ensure that everything you act, do, say, and generate matches with this fact.'

# Configuration for the different tasks
[tasks]
context_styles = [ # Used contextual tasks (e.g. summarization, translation)
    "news article",
    "blog post",
    "text messages",
    "fictional short story",
    "video transcript",
    "song",
    "poem",
    "scientific study",
    "medical report",
    "social media post with replies",
    "email",
    "tweet",
    "how-to article"
]

    [tasks.question_answering]
    count = 500
    batch_size = 10

    temperature = 0.35
    max_tokens = 1000

    [tasks.multiple_choice]
    count = 1750
    batch_size = 10

    temperature = 0.4
    max_tokens = 4000

    [tasks.summarization]
    count = 1500
    batch_size = 10
    summary_styles = [
        "bullet point",
        "paragraph",
        "numbered list",
    ]

    [tasks.translation]
    count = 250
    batch_size = 10

    [tasks.creative_writing]
    count = 1250
    batch_size = 10

    [tasks.conversation]
    count = 2000 
    batch_size = 10

    temperature = 0.8
    max_tokens = 1500

    [tasks.jokes]
    count = 500
    batch_size = 10

    temperature = 0.5
    max_tokens = 1500

[cleaning] # Configuration for the cleaning process
remove_duplicates = true
remove_empty_instructions = true
remove_empty_outputs = true

use_cosine_filter = true
cosine_similarity_threshold = 0.95
embed_model = "BAAI/bge-m3"

[quality_control]
temperature = 0.8
max_tokens = 1500