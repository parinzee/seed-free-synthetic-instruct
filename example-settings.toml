[model]
anthropic.api_key = 'YOUR_API_KEY'
anthropic.model = 'claude-3-sonnet-20240229'
anthropic.use = true # Use the Anthropic model to generate data

openai.api_key = 'YOUR_API_KEY'
openai.model = 'gpt-4-turbo'
openai.use = false # Use the OpenAI model to generate data (cannot be used with the Anthropic model)

[general]
output_dir = 'output'
language = 'en'
wiki_lang = 'en' # Language to use for the Wikipedia API
use_wiki = true # Use the Wikipedia API to get articles for the tasks

num_topics = 200
topic_generation_temperature = 0.7
topic_generation_max_tokens = 400

llm_task_types = [
    'question_answering',
    'multiple_choice',
    'summarization',
    'translation',
    'creative_writing',
    'conversation',
    'jokes',
    'debate'
]

# Filters to apply to the response
response_filters = [
  'my programming',
  'openai',
  'language model',
  'large language',
  'as an? (ai|generative language|gpt|bot)',
  'illegal and dangerous',
  "i do(n't| not) (possess|have|exhibit) (personal|consciousness|subjective)",
  'personal (feelings|thoughts|emotions|desires|experiences|goals|objective|belief)',
  "(can('t| ?not)|w(on't|will not)|unable.?) (\\w+\\s)+(with (that|your)|your \\w+|provide)",
  'my limitations',
  'the limitations of my',
  'my abilities',
  'violates my',
  "i (can('t| ?not)|w(on't|will not)|am (not |un)able.?).{0,30}(you are|you're|your )",
  'please note that',
  'flesch'
]

[culture]
enabled = true
prompt = 'You are a native Thai person with expert knowledge of Thai culture, history, language, and customs. Ensure that everything you act, do, say, and generate matches with this fact.'

# Configuration for the different tasks
[tasks]
context_styles = [ # Used contextual tasks (e.g. summarization, translation)
    "news article",
    "blog post",
    "text messages",
    "fictional short story",
    "video transcript",
    "song",
    "poem",
    "scientific study",
    "medical report",
    "social media post with replies",
    "email",
    "tweet",
    "how-to article"
]

    [tasks.question_answering]
    count = 500
    batch_size = 10

    temperature = 0.35
    max_tokens = 1000

    [tasks.multiple_choice]
    count = 250
    batch_size = 10

    [tasks.summarization]
    count = 350
    batch_size = 10

    [tasks.translation]
    count = 250
    batch_size = 10

    [tasks.creative_writing]
    count = 1250
    batch_size = 10

    [tasks.conversation]
    count = 750
    batch_size = 10

    [tasks.jokes]
    count = 250
    batch_size = 10